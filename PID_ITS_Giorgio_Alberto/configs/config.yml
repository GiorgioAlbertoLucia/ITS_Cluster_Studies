
# Configuration file for the particle identification with the ML algorithm in PID_ITS - Giorgio Alberto

# NOTA: /data/shared/ITS/ML/particles_pid_520143.parquet Ã¨ il dataset ripulito

input:
    data:       /data/shared/ITS/ML/particles_pid_520143_itstpc.parquet 
                #/data/shared/ITS/ML/NEW/particles_pid_520143.parquet
                #
                
    appl_data:  /data/shared/ITS/ML/particles_pid_520147_itstpc.parquet
    ext_appl: True

    isV0: False
    hybrid: False    # hybrid true requires isV0 true
    isMC: False     # MC true requires isV0 true
    MCtpc: False     # MCtpc true requires isV0 true and isMC true



output:
    data_visual_dir:    ../../../data_visual_root
    ml_dir:             ../../../ML_output
    final_dir:          ../../../final_plots

    save_data_dir:      ../../../data
    model_out:          ../../../ML_output 

    particle:   { 0: "Deu", 1: "P", 2: "K", 3: "Pi"}
    #particle:   { 1: "P", 2: "K", 3: "Pi", 4: "E"}


data_prep:

    skip_data_prep: False
    prep_data: [/Users/giogi/Desktop/Stage INFN/PID ITS/data/TrainSet_augm.parquet.gzip,
                /Users/giogi/Desktop/Stage INFN/PID ITS/data/yTrain_augm.parquet.gzip,
                /Users/giogi/Desktop/Stage INFN/PID ITS/data/TestSet_augm.parquet.gzip,
                /Users/giogi/Desktop/Stage INFN/PID ITS/data/yTest_betaflataugm.gzip]
    appl_data:  /Users/giogi/Desktop/Stage INFN/PID ITS/data/ApplicationDf_augm.parquet.gzip
    save_data: True

    test_frac: 0.2
    seed_split: 0   # random_state for train_test_split

    # Seven Hits (only consider candidates with hits on all the layeres)
    #___________________________________
    seven_hits: False
 
    # Equal
    #___________________________________
    do_equal: False


    # Data Augmentation
    #____________________________________
    do_augm: False
    to_augm: ["K"]
    mothers: ["P"]
    #p_ranges: [[0., 0.2]]
    p_ranges: [[0.2, 1.5]]

    # Beta Flat
    #____________________________________
    betamins: [0.2, 0.4, 0.6, 0.8]
    betamaxs: [0.4, 0.6, 0.8, 1.0]

    # Beta p Flat
    #____________________________________
    pmins: [0., 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.15, 1.2, 1.25, 1.3, 1.35, 1.4, 1.45]
    pmaxs: [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.15, 1.2, 1.25, 1.3, 1.35, 1.4, 1.45, 1.5]

training:

    skip_training: False

    random_state: 0
    
    RegressionColumns: ["p", 
                        "tgL", "meanPattID", "clSizeCosLam",
                        "ClSizeL0", "ClSizeL1", "ClSizeL2", "ClSizeL3", "ClSizeL4", "ClSizeL5", "ClSizeL6"]
    RegressionRanges:   [[200, 0, 2],
                        [80, -4, 4], [10, 0, 100], [250, 0, 25],
                        [25, 0, 25], [25, 0, 25], [25, 0, 25], [25, 0, 25], [25, 0, 25], [25, 0, 25], [25, 0, 25]]
    ModelParams:        {"n_jobs": 40,
                        #"time_budget": 100,
                        #"metric": "r2",
                        #"task": "regression",
                        #"log_file_name": "bdt.log",
                        "tree_method": "hist", # not available in FLAML
                        #"estimator_list" : ["xgboost"], # not available in FLAML
                        "colsample_bylevel": 0.6337942873486531, # not available in FLAML 
                        "colsample_bytree": 0.7, # not available in FLAML
                        "subsample": 0.710841077866278, # not available in FLAML
                        "learning_rate": 0.04952863262192068, # not available in FLAML
                        "n_estimators": 400, # not available in FLAML
                        "max_depth": 13, # not available in FLAML
                        "min_child_weight": 10, # not available in FLAML
                        "eval_metric": "rmse", # not available in FLAML
                        "reg_alpha": 0.349923237394973, # not available in FLAML
                        "reg_lambda": 0.5031161568154017, # not available in FLAML
                        "verbosity": 1,
                        } # dict of hyperparameters (XGB and AUTOML USE DIFFERENT HYPER-PARS!)

    HyperParamsRange:   {"max_depth": [3, 15], 
                        "learning_rate": [0.01, 0.1],
                        "n_estimators": [300, 1500], 
                        "min_child_weight":[1, 10],
                        "subsample": [0.8, 1.], 
                        "colsample_bytree": [0.8, 1],
                        }                      # dict of ranges for the hyperparameters evaluated by optuna

    model: "xgboost"        # accepted models: xgboost, automl
    do_opt: True
    early_stop: False
    save_model: True

    beta_flat: False
    beta_p_flat: False
    MCweights: False

application:
    skip_appl: False
    model_loc: /home/galucia/PID_ITS/ML_output/hybrid/RegressorModel_xgboost_beta_pflat_.pickle

plots:
    do_plots: True
    vars_to_plot:   ["ClSizeL0", "ClSizeL1", "ClSizeL2", "ClSizeL3", "ClSizeL4", "ClSizeL5", "ClSizeL6", "clSizeCosLam",
                    "meanSnPhi", "tgL", "meanPattID", "p", "pITS", 
                    "pTPC", "tpcITSchi2", "nClusTPC"
                    ]
    #vars_to_plot:   ["ClSizeL0", "ClSizeL1", "ClSizeL2", "ClSizeL3", "ClSizeL4", "ClSizeL5", "ClSizeL6", "meanClsize",
    #                "meanSnPhi", "tgL", "meanPattID", "p", "clSizeCosLam"]

    plot_spec_hist: {"ClSizeL0": [25, 0, 25], "ClSizeL1": [25, 0, 25], "ClSizeL2": [25, 0, 25], "ClSizeL3": [25, 0, 25], 
                    "ClSizeL4": [25, 0, 25], "ClSizeL5": [25, 0, 25], "ClSizeL6": [25, 0, 25], "clSizeCosLam": [250, 0, 25],
                    "SnPhiL0": [100, -1, 1], "SnPhiL1": [100, -1, 1], "SnPhiL2": [100, -1, 1], "SnPhiL3": [100, -1, 1], 
                    "SnPhiL4": [100, -1, 1], "SnPhiL5": [100, -1, 1], "SnPhiL6": [100, -1, 1], "meanSnPhi": [100, -1, 1], 
                    "TanLamL0": [80, -4, 4], "TanLamL1": [80, -4, 4], "TanLamL2": [80, -4, 4], "TanLamL3": [80, -4, 4], 
                    "TanLamL4": [80, -4, 4], "TanLamL5": [80, -4, 4], "TanLamL6": [80, -4, 4], "tgL": [80, -4, 4],
                    "PattIDL0": [10, 0, 100], "PattIDL1": [10, 0, 100], "PattIDL2": [10, 0, 100], "PattIDL3": [10, 0, 100], 
                    "PattIDL4": [10, 0, 100], "PattIDL5": [10, 0, 100], "PattIDL6": [10, 0, 100], "meanPattID": [100, 0, 100],
                    "L6_L0": [100, 0, 10], "p": [200, 0, 2], "pITS": [150, 0, 1.5], 
                    "pTPC": [150, 0, 1.5], "tpcITSchi2": [100, 0, 10], "nClusTPC": [130, 50, 180]
                    }     # dict (variable_to_plot, hist_settings) 
    
    plot_x_scat:    [
                    "p", 
                    "p", "p", "beta"]
    plot_y_scat:    [
                    "dedx", 
                    "beta", "clSizeCosLam", "clSizeCosLam"]
    plot_spec_scat: [
                    ["p [GeV/c]", "#frac{dE}{dx} [keV/300#mum]", 700, 0, .7, 600, 0, 600], 
                    ["p [GeV/c]", "#beta", 1500, 0, 1.5, 1100, 0, 1.1], ["p [GeV/c]", "<Cl. size> <cos#lambda>", 150, 0, 1.5, 120, 0, 12], ["#beta", "<Cl. size> <cos#lambda>", 100, 0, 1, 120, 0, 12]] 
    bp_flat_scat:   {"p": ["p", "Particle species", 30, 0, 1.5, 4, 0., 4.5], "weights": ["weights", "Particle species", 100, 0, 1, 4, 0., 4.5]}

    model_train:    {"p": [150, 0, 1.5, 300, -1.5, 1.5], "beta": [100, 0, 1, 300, -1.5, 1.5]}
    appl_plot_spec: {"b_vs_p_final": ["p [GeV/c]", "#beta (ML)", 1500, 0, 1.5, 1050, 0, 1.05], "b_vs_p_true": ["p [GeV/c]", "#beta (ML)", 1500, 0, 1.5, 1050, 0, 1.05], 
                    "dedx_vs_p": ["p [GeV/c]", "#frac{dE}{dx} [keV/300#mum]", 150, 0, 1.5, 600, 0, 600], 
                    "beta": [100, 0, 1, 300, -1.5, 1.5], "p": [150, 0, 1.5, 300, -1.5, 1.5]} 